---
title: "STAT 432 Final Project"
subtitle: "Detecting Volcanoes on Venus via Classification (Where are the Volcanoes?!!)"
author: 
- 'Team : Mamamia!'
- "Di Ye (diye2), Hao Wang (haow2),Hannah Pu (chpu2)"
date: "November 17, 2018"
output:
  pdf_document:
    toc: yes
---

# Final Report

## Introduction and literature review

### Data Source information:

- The data was downloaded from Kaggle, which is originally from NASA's Magellan spacecraft database.
- Kaggle. https://www.kaggle.com/amantheroot/finding-volcanoes-on-venus/data

### Data introduction:

9734 images were captured by the spacecraft and converted to pixel (110x110, from 0 to 255), where every image is one row of 12100 columns (all the 110 rows of 110 columns). Images can contain more than one volcanoes or maybe none.
The 9000+ images are separated to four datasets (file names : *train_images*, *train_labels*, *test_images*, and *test_labels*):

#### Image dataset (*train_images* and *test_images*)
*Train_images* : 7000 images as train data with 12100 variables;  
*Test_images* : 2734 images as test data with 12100 variables; 
All the variables correspond to the pixel image, 110 pixel * 110 pixel = 12100.

#### Label dataset (*tain_labels* and *test_labels*)
Both *train_labels* and *test_label* datasets include the following labels:   
1. *Volcano?* : if in the image there are volcanoes (Main target), 1 (yes) or 0 (no)  
(If Volcano? = 0, the following three categories would be "nan")  
2. *Type* : 1= definitely a volcano,2 =probably, 3= possibly, 4= only a pit is visible   
3. *Radius* : is the radius of the volcano in the center of the image, in pixels   
4. *Number Volcanoes* : The number of volcanoes in the image  
For this project, we will focus mainly on predicting whether each image has a volcanoe or not. In addition, if the classification prediction goes well, we will also construct model to predict the number of volcanoes in the images. 

### Scientific goal:

We aim in constructing classification model to predict whether there exist a valcano through image. Identifying valcano through IT technology would increase the efficency of space exploration and safty of the crews. 


### Literature review:

In the Kaggle, the data analysis of the project is done in Python. People have already had vivid data visualization and exploratory data. Different methods have been used, such as Convolutional Neural Network (CNN) and VGG Neural Network for deep learning. People have reached the 95% accuracy. 

```{r}
#################
# load datasets #
#################
load("test_data.RData")
load("train_data.Rdata")

train_y <- read.csv("train_labels.csv", header = TRUE)
test_y <- read.csv("test_labels.csv", header = TRUE)

###################
# Check dimension #
###################
# train image file (no header) : 7000*12100
# train label file (no header) : 7000*4
# test image file (no header) : 2734*12100
# test label file (header) : 2734*4
cat("The dimension of the train image file is:", dim(train_data))
cat("The dimension of the test image file is:", dim(test_data))
cat("The dimension of the train label file is:", dim(train_y))
cat("The dimension of the test label file is:", dim(test_y))

########################
# check missing values #
########################
#only y has NAs
colnames(train_data)[colSums(is.na(train_data)) > 0]
colnames(train_y)[colSums(is.na(train_y)) > 0]
colnames(test_data)[colSums(is.na(test_data)) > 0]
colnames(test_y)[colSums(is.na(test_y)) > 0]
cat("Only labels have NAs.")

# test_y has 2300 missing observations
# train_y has 6000 missing observations
cat("test_y has", sum(is.na(test_y$Type)), "missing observations.")
cat("train_y has", sum(is.na(train_y$Type)), "missing observations.")

# set the missing values to 0
test_y[is.na(test_y$Type), ] <- 0
test_y[is.na(test_y$Radius), ] <- 0
train_y[is.na(train_y$Type), ] <- 0
train_y[is.na(train_y$Radius), ] <- 0

#######
# EDA #
#######
##plot
## trainset rows that have volcanoes: 1,10,16,30,35,39

volplot <- function(data, obs){
  im <- as.numeric(data[obs,])
  # im <- sapply(train_data[obs, ], as.numeric)
  m <- matrix(im, nrow = 110, byrow = TRUE)
  image(m, col = grey((0:255)/255))
}
```

```{r}
library(keras)
```

```{r}
## use 200 images for toy model
train_images <- array(NA, c(2000, 110, 110))
train_data_num <- sapply(train_data[1:2000,], as.numeric)
for (i in 1:2000) {
  train_images[i,,] <- array_reshape(train_data_num[i,], c(110, 110))
}
train_images <- array_reshape(train_images, c(2000, 110, 110, 1))
train_images <- train_images / 255

test_images <- array(NA, c(400, 110, 110))
test_data_num <- sapply(test_data[1:400,], as.numeric)
for (i in 1:400) {
  test_images[i,,] <- array_reshape(test_data_num[i,], c(110, 110))
}
test_images <- array_reshape(test_images, c(400, 110, 110, 1))
test_images <- test_images / 255

train_y_volcano <- to_categorical(train_y$Volcano.[1:2000])
test_y_volcano <- to_categorical(test_y$Volcano.[1:400])
```

```{r}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu", input_shape = c(110, 110, 1)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  # layer_dropout(rate = 0.2) %>%
  layer_conv_2d(filters = 16, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  # layer_dropout(rate = 0.3) %>% 
  layer_conv_2d(filters = 16, kernel_size = c(3, 3), activation = "relu") %>%
  layer_flatten() %>% # flatten 3D to 1D
  # layer_dense(units = 16, activation = "relu") %>%
  layer_dense(units = 2, activation = "softmax")

model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

model %>% fit(
  train_images, train_y_volcano,
  epochs = 30, batch_size=32,
  validation_split = 0.2
)

results <- model %>% evaluate(test_images, test_y_volcano)
results
model %>% predict_classes(test_images)
```

## Methods
Models we used:
Lasso
ElasticNet
### Evaluation metric
Our models were evaluated by calculating the classification error coded as following:
```{r}
predfunc= function(a){
  mean(as.numeric(a > 0.5) == test_y[,1])*100
}
predfunc_train = function(a){
  mean(as.numeric(a > 0.5) == train_y[,1])*100
}
```


## Results and Discussion

### Challenges encountered
Our dataset is pretty large, and the number of variables (12100 variables) are larger than observations (2734 observations).

### Results of model and analysis to predict whether there is volcanoe or not
#### Lasso
Using Lasso to predict, first tune with `cv.glmnet`, then use `lambda.min` to fit lasso model and do prediction on test data. The classification accuracy on test data is 92.4%. Training error was calculated to be 77.5%, therefore there seemes to be no overfitting.
```{r}
library(glmnet)
train.x = as.matrix(train_data)
train.y=as.matrix(train_y[,1])
lam.seq = exp(seq(-6.5, -5, length=100))
cv.out = cv.glmnet(x=train.x, y=train.y, alpha = 1, family = "binomial", lambda = lam.seq)
lasmodel = glmnet(x=train.x, y=train.y, alpha = 1, family = "binomial", lambda = cv.out$lambda.min)
pred = predict(lasmodel, newx=as.matrix(test_data), type = "response")
```
Testing error:
```{r}
pred.cal = apply(pred, 2, predfunc)
pred.cal
table(as.numeric(pred > 0.5), test_y[,1])
```
Training error:
```{r}
pred_train = predict(lasmodel, newx=as.matrix(train_data),type = "response")
pred.cal.train = apply(pred, 2, predfunc_train)
pred.cal.train
table(as.numeric(pred_train > 0.5), train_y[,1])
```
In total, 405 variables were selected by Lasso. Selected variables spread accross the 110*110 pixel images.
```{r}
mylasso.coef = predict(lasmodel, s = cv.out$lambda.min, type = "coefficients")
sum(mylasso.coef != 0) - 1 
var.sel = row.names(mylasso.coef)[nonzeroCoef(mylasso.coef)[-1]]
var.sel
```


## References









