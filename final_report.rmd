---
title: "STAT 432 Final Project"
subtitle: "Detecting Volcanoes on Venus via Classification (Where are the Volcanoes?!!)"
author: 
- 'Team : Mamamia!'
- "Di Ye (diye2), Hao Wang (haow2),Hannah Pu (chpu2)"
date: "November 17, 2018"
output:
  pdf_document:
    toc: yes
---

# Final Report

## Introduction and literature review

### Data Source information:

- The data was downloaded from Kaggle, which is originally from NASA's Magellan spacecraft database.
- Kaggle. https://www.kaggle.com/amantheroot/finding-volcanoes-on-venus/data

### Data introduction:

9734 images were captured by the spacecraft and converted to pixel (110x110, from 0 to 255), where every image is one row of 12100 columns (all the 110 rows of 110 columns). Images can contain more than one volcanoes or maybe none.
The 9000+ images are separated to four datasets (file names : *train_images*, *train_labels*, *test_images*, and *test_labels*):

#### Image dataset (*train_images* and *test_images*)
*Train_images* : 7000 images as train data with 12100 variables;  
*Test_images* : 2734 images as test data with 12100 variables; 
All the variables correspond to the pixel image, 110 pixel * 110 pixel = 12100.

#### Label dataset (*tain_labels* and *test_labels*)
Both *train_labels* and *test_label* datasets include the following labels:   
1. *Volcano?* : if in the image there are volcanoes (Main target), 1 (yes) or 0 (no)  
(If Volcano? = 0, the following three categories would be "nan")  
2. *Type* : 1= definitely a volcano,2 =probably, 3= possibly, 4= only a pit is visible   
3. *Radius* : is the radius of the volcano in the center of the image, in pixels   
4. *Number Volcanoes* : The number of volcanoes in the image  
For this project, we will focus mainly on predicting whether each image has a volcanoe or not. In addition, if the classification prediction goes well, we will also construct model to predict the number of volcanoes in the images. 

### Scientific goal:

We aim in constructing classification model to predict whether there exist a valcano through image. Identifying valcano through IT technology would increase the efficency of space exploration and safty of the crews. 


### Literature review:

In the Kaggle, the data analysis of the project is done in Python. People have already had vivid data visualization and exploratory data. Different methods have been used, such as Convolutional Neural Network (CNN) and VGG Neural Network for deep learning. People have reached the 95% accuracy. 

```{r}
#################
# load datasets #
#################
load("test_data.RData")
load("train_data.Rdata")

train_y <- read.csv("train_labels.csv", header = TRUE)
test_y <- read.csv("test_labels.csv", header = TRUE)

###################
# Check dimension #
###################
# train image file (no header) : 7000*12100
# train label file (no header) : 7000*4
# test image file (no header) : 2734*12100
# test label file (header) : 2734*4
cat("The dimension of the train image file is:", dim(train_data))
cat("The dimension of the test image file is:", dim(test_data))
cat("The dimension of the train label file is:", dim(train_y))
cat("The dimension of the test label file is:", dim(test_y))

########################
# check missing values #
########################
#only y has NAs
colnames(train_data)[colSums(is.na(train_data)) > 0]
colnames(train_y)[colSums(is.na(train_y)) > 0]
colnames(test_data)[colSums(is.na(test_data)) > 0]
colnames(test_y)[colSums(is.na(test_y)) > 0]
cat("Only labels have NAs.")

# test_y has 2300 missing observations
# train_y has 6000 missing observations
cat("test_y has", sum(is.na(test_y$Type)), "missing observations.")
cat("train_y has", sum(is.na(train_y$Type)), "missing observations.")

# set the missing values to 0
test_y[is.na(test_y$Type), ] <- 0
test_y[is.na(test_y$Radius), ] <- 0
train_y[is.na(train_y$Type), ] <- 0
train_y[is.na(train_y$Radius), ] <- 0

#######
# EDA #
#######
##plot
## trainset rows that have volcanoes: 1,10,16,30,35,39

volplot <- function(data, obs){
  im <- as.numeric(data[obs,])
  # im <- sapply(train_data[obs, ], as.numeric)
  m <- matrix(im, nrow = 110, byrow = TRUE)
  image(m, col = grey((0:255)/255))
}
```

```{r}
library(keras)
```

```{r}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", input_shape = c(110, 110, 1)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_flatten() %>% # flatten 3D to 1D
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")

train_images <- array(NA, c(110, 110, 7000))
for (i in 1:7000) {
  train_images[,,i] <- array_reshape(as.numeric(train_data[i,]), c(110, 110))
  # 95  101   99  103   95   86   96   89   70   104   115    96    89   102   109
}
test_images <- sapply(test_data, as.numeric)
m <- sapply(test_images, matrix, nrow = 110, byrow = TRUE)
m <- matrix(im, nrow = 110, byrow = TRUE)
for (i in 1:2734) {
  test_images[i,,]
}
c(c(train_images, train_labels), c(test_images, test_labels)) %<-% mnist
train_images <- array_reshape(as.numeric(train_data), c(7000, 110, 110))
train_images <- train_images / 255

test_images <- sapply(test_data, as.numeric)
test_images <- array_reshape(test_images, c(2734, 110, 110))
test_images <- test_images / 255
train_labels <- to_categorical(train_y[,1])
test_labels <- to_categorical(test_y[,1])

model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

model %>% fit(
  train_images, train_labels,
  epochs = 5, batch_size=64
)

results <- model %>% evaluate(test_images, test_labels)
results

```

